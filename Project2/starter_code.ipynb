{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1： 模型理论与应用\n",
    "在第一部分主要以证明和推导为主。以下几个问题都是比较经典的问题，会对模型的深入理解会有很大的帮助。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.1 逻辑回归相关 (30分)\n",
    "假设我们有训练数据$D=\\{(\\mathbf{x}_1,y_1),...,(\\mathbf{x}_n,y_n)\\}$, 其中$(\\mathbf{x}_i,y_i)$为每一个样本，而且$\\mathbf{x}_i$是样本的特征并且$\\mathbf{x}_i\\in \\mathcal{R}^D$, $y_i$代表样本数据的标签（label）, 取值为$0$或者$1$. 在逻辑回归中，模型的参数为$(\\mathbf{w},b)$。对于向量，我们一般用粗体来表达。请回答以下问题。最好用Markdown自带的Latex来编写。（如果实在不行，可以手写然后拍照完放入word或者转成PDF，作为独立的文件来提交）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) 在逻辑回归模型下，请写出目标函数（objective function）, 也就是我们需要\"最小化\"的目标（也称之为损失函数或者loss function)，不需要考虑正则 （3分）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$L(\\mathbf{w},b)=argmin(-\\sum_{i=1}^{n}y\\log{[p(y=1|x,w)]}+(1-y)\\log{[1-p(y=1|x,w)]})$$\n",
    "其中$p(y=1|x,w)=\\frac{1}{1+e^{-w^{T}x+b}}=\\sigma (w^{T}x+b)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) 求出$L(\\mathbf{w},b)$的梯度（或者计算导数），需要必要的中间过程。（5分）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\partial L(\\mathbf{w},b)}{\\partial \\mathbf{w}}=\\sum_{i=1}^{n}[\\sigma(w^{T}x+b)-y_{i}]x_{i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\partial L(\\mathbf{w},b)}{\\partial b}=\\sum_{i=1}^{n}[\\sigma(w^{T}x+b)-y_{i}]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) 请写出基于梯度下降法（batch）的对于$\\mathbf{w}$和$b$的更新 （5分）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$w^{t+1}=w^{t}-\\eta \\frac{\\partial L(\\mathbf{w},b)}{\\partial \\mathbf{w}}$\n",
    "\n",
    "$b^{t+1}=b^{t}-\\eta $\\frac{\\partial L(\\mathbf{w},b)}{\\partial b}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) 假设在(a)的基础上加了一个L2正则项，请写出基于梯度下降法（batch）的对于$\\mathbf{w}$和$b$的更新 （5分）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$w^{t+1}=$\n",
    "\n",
    "$b^{t+1}=$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们来证明逻辑回归函数是凸函数。假设一个函数是凸函数，我们则可以得出局部最优解即为全局最优解，所以假设我们通过随机梯度下降法等手段找到最优解\n",
    "时我们就可以确认这个解就是全局最优解。证明凸函数的方法有很多种，在这里我们介绍一种方法，就是基于二次求导大于等于0。比如给定一个函数$f(x)=x^2-3x+3$，做两次\n",
    "求导之后即可以得出$f''(x)=2 > 0$，所以这个函数就是凸函数。类似的，这种理论也应用于多元变量中的函数上。在多元函数上，只要证明二阶导数是posititive semidefinite即可以。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) 在(b)的基础上接着对$\\mathbf{w}$求导（等于二阶导数，二阶导数的维度为$D\\times D$），这个二阶导数也称之为Hessian Matrix(https://en.wikipedia.org/wiki/Hessian_matrix) 对于矩阵、向量的求导请参考：https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf （8分）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\partial^2 \\mathcal{L}}{\\partial^2 \\mathbf{w}}=$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) 请说明在(e)的得出来的Hessian Matrix是Positive Definite. 提示：为了证明一个$D\\times D$的矩阵$H$为Positive Semidefinite，需要证明对于任意一个非零向量$v\\in \\mathcal{R}^D$, 需要得出$v^{T}Hv >=0$ （4分）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请推导或者说明："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2： 情感分析项目 (70分)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本项目的目标是基于用户提供的评论，通过算法自动去判断其评论是正面的还是负面的情感。比如给定一个用户的评论：\n",
    "- 评论1： “我特别喜欢这个电器，我已经用了3个月，一点问题都没有！”\n",
    "- 评论2： “我从这家淘宝店卖的东西不到一周就开始坏掉了，强烈建议不要买，真实浪费钱”\n",
    "\n",
    "对于这两个评论，第一个明显是正面的，第二个是负面的。 我们希望搭建一个AI算法能够自动帮我们识别出评论是正面还是负面。\n",
    "\n",
    "情感分析的应用场景非常丰富，也是NLP技术在不同场景中落地的典范。比如对于一个证券领域，作为股民，其实比较关注舆论的变化，这个时候如果能有一个AI算法自动给网络上的舆论做正负面判断，然后把所有相关的结论再整合，这样我们可以根据这些大众的舆论，辅助做买卖的决策。 另外，在电商领域评论无处不在，而且评论已经成为影响用户购买决策的非常重要的因素，所以如果AI系统能够自动分析其情感，则后续可以做很多有意思的应用。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "情感分析是文本处理领域经典的问题。整个系统一般会包括几个模块：\n",
    "- 数据的抓取： 通过爬虫的技术去网络抓取相关文本数据\n",
    "- 数据的清洗/预处理：在本文中一般需要去掉无用的信息，比如各种标签（HTML标签），标点符号，停用词等等\n",
    "- 把文本信息转换成向量： 这也成为特征工程，文本本身是不能作为模型的输入，只有数字（比如向量）才能成为模型的输入。所以进入模型之前，任何的信号都需要转换成模型可识别的数字信号（数字，向量，矩阵，张量...)\n",
    "- 选择合适的模型以及合适的评估方法。 对于情感分析来说，这是二分类问题（或者三分类：正面，负面，中性），所以需要采用分类算法比如逻辑回归，朴素贝叶斯，神经网络，SVM等等。另外，我们需要选择合适的评估方法，比如对于一个应用，我们是关注准确率呢，还是关注召回率呢？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本次项目中，我们已经给定了训练数据和测试数据，它们分别是 train.positive.txt, train.negative.txt， test_combined.txt. 请注意训练数据和测试数据的格式不一样，详情请见文件内容。 整个项目你需要完成以下步骤：\n",
    "\n",
    "数据的读取以及清洗： 从给定的.txt中读取内容，并做一些数据清洗，这里需要做几个工作： （1） 文本的读取，需要把字符串内容读进来。 （2）去掉无用的字符比如标点符号，多余的空格，换行符等 （3） 分词\n",
    "把文本转换成TF-IDF向量： 这部分直接可以利用sklearn提供的TfidfVectorizer类来做。\n",
    "利用逻辑回归模型来做分类，并通过交叉验证选择最合适的超参数\n",
    "利用支持向量机做分类，并通过交叉验证选择神经网络的合适的参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Reading: 文本读取 （5分）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "def create_train_data(path,label):\n",
    "    datas=[]\n",
    "    labels=[]\n",
    "    f=open(path,encoding='utf-8')\n",
    "    content=f.read()\n",
    "    f.close()\n",
    "    tree=etree.HTML(content)\n",
    "    nodes=tree.xpath(\"//review/text()\")\n",
    "    datas=nodes\n",
    "    labels=[label]*len(datas)\n",
    "    \n",
    "    return datas,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all_train_data(train_pos_file,train_neg_file):\n",
    "    pos_datas,pos_labels=create_train_data(train_pos_file,1)\n",
    "    neg_datas,neg_labels=create_train_data(train_neg_file,0)\n",
    "    datas=pos_datas+neg_datas\n",
    "    labels=pos_labels+neg_labels\n",
    "    return datas,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all_test_data(path):\n",
    "    f=open(path,encoding='utf-8')\n",
    "    content=f.read()\n",
    "    f.close()\n",
    "    tree=etree.HTML(content)\n",
    "    nodes=tree.xpath(\"//review/text()\")\n",
    "    labels=tree.xpath(\"//review/@label\")\n",
    "    \n",
    "    \n",
    "    return nodes,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file():\n",
    "    \"\"\"\n",
    "    读取训练数据和测试数据，并对它们做一些预处理\n",
    "    \"\"\"    \n",
    "    train_pos_file = \"data/train_positive.txt\"\n",
    "    train_neg_file = \"data/train_negative.txt\"\n",
    "    test_comb_file = \"data/test_combined.txt\"\n",
    "    \n",
    "    # TODO: 读取文件部分，把具体的内容写入到变量里面\n",
    "    train_comments = []\n",
    "    train_labels = []\n",
    "    test_comments = []\n",
    "    test_labels = []\n",
    "    \n",
    "    train_comments,train_labels=create_all_train_data(train_pos_file,train_neg_file)\n",
    "    test_comments,test_labels=create_all_test_data(test_comb_file)\n",
    "    \n",
    "    return train_comments,train_labels,test_comments,test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_comments,train_labels,test_comments,test_labels=process_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explorary Analysis: 做一些简单的可视化分析 （10分） "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8065 2500\n"
     ]
    }
   ],
   "source": [
    "# 训练数据和测试数据大小\n",
    "print (len(train_comments), len(test_comments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 对于训练数据中的正负样本，分别画出一个histogram， histogram的x抽是每一个样本中字符串的长度，y轴是拥有这个长度的样本的百分比。\n",
    "#       并说出样本长度是否对情感有相关性 (需要先用到结巴分词)\n",
    "#       参考：https://en.wikipedia.org/wiki/Histogram\n",
    "t_datas=train_comments.copy()\n",
    "t_labels=train_labels.copy()\n",
    "\n",
    "t_datas=np.array(t_datas)\n",
    "t_labels=np.array(t_labels)\n",
    "\n",
    "pos_data=t_datas[t_labels==1]\n",
    "neg_data=t_datas[t_labels==0]\n",
    "\n",
    "pos_x=[]\n",
    "neg_x=[]\n",
    "\n",
    "for line in pos_data:\n",
    "    l=len(line)\n",
    "    pos_x.append(l)\n",
    "\n",
    "for line in neg_data:\n",
    "    l=len(line)\n",
    "    neg_x.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4359.,  379.,   86.,   41.,   26.,   20.,   11.,   11.,   10.,\n",
       "          57.]),\n",
       " array([   8. ,  107.9,  207.8,  307.7,  407.6,  507.5,  607.4,  707.3,\n",
       "         807.2,  907.1, 1007. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAD2hJREFUeJzt3X+s3XV9x/Hny1Zx08wWuZqubXYxNpu4RCEN1rk/DDioaCx/QFJiZuOa9B+W4WLiYPuD+IMEkkXQZBKJdFZjrAzJaJCMNAWz7A+BMhwClfUqTO5g9pIWnDMaq+/9cT4Xj/W290dv7/Wez/ORnJzv5/39nHs+n/tp+jrf7/mec1NVSJL684rlHoAkaXkYAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROrV7uAZzKOeecU+Pj48s9DElaUR555JEXqmpstn6/1QEwPj7OwYMHl3sYkrSiJPmvufTzFJAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXqt/qTwKdr/NpvLMvzPnPj+5bleSVpPjwCkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKn5hwASVYleTTJPa19bpIHkxxO8rUkr2r1s1p7ou0fH/oZ17X6U0kuXezJSJLmbj5HANcAh4baNwE3V9Um4Biws9V3Aseq6s3Aza0fSc4DtgNvBbYCn0uy6vSGL0laqDkFQJINwPuAL7R2gIuAO1uXPcDlbXtba9P2X9z6bwP2VtXPquppYAK4cDEmIUmav7keAdwCfAz4ZWu/Hnixqo639iSwvm2vB54FaPtfav1frs/wGEnSEps1AJK8HzhSVY8Ml2foWrPsO9Vjhp9vV5KDSQ5OTU3NNjxJ0gLN5QjgXcAHkjwD7GVw6ucWYE2S6b8otgF4rm1PAhsB2v7XAUeH6zM85mVVdVtVba6qzWNjY/OekCRpbmYNgKq6rqo2VNU4gzdx76+qDwIPAFe0bjuAu9v2vtam7b+/qqrVt7erhM4FNgEPLdpMJEnzcjp/E/hvgL1JPgU8Ctze6rcDX04yweCV/3aAqnoiyR3Ak8Bx4Oqq+sVpPL8k6TTMKwCq6pvAN9v295nhKp6q+ilw5UkefwNww3wHKUlafH4SWJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE7NGgBJXp3koST/keSJJB9v9XOTPJjkcJKvJXlVq5/V2hNt//jQz7qu1Z9KcumZmpQkaXZzOQL4GXBRVb0NeDuwNckW4Cbg5qraBBwDdrb+O4FjVfVm4ObWjyTnAduBtwJbgc8lWbWYk5Ekzd2sAVADP27NV7ZbARcBd7b6HuDytr2ttWn7L06SVt9bVT+rqqeBCeDCRZmFJGne5vQeQJJVSb4NHAH2A98DXqyq463LJLC+ba8HngVo+18CXj9cn+Exw8+1K8nBJAenpqbmPyNJ0pzMKQCq6hdV9XZgA4NX7W+ZqVu7z0n2nax+4nPdVlWbq2rz2NjYXIYnSVqAeV0FVFUvAt8EtgBrkqxuuzYAz7XtSWAjQNv/OuDocH2Gx0iSlthcrgIaS7Kmbf8O8B7gEPAAcEXrtgO4u23va23a/vurqlp9e7tK6FxgE/DQYk1EkjQ/q2fvwjpgT7ti5xXAHVV1T5Ingb1JPgU8Ctze+t8OfDnJBINX/tsBquqJJHcATwLHgaur6heLOx1J0lzNGgBV9Rhw/gz17zPDVTxV9VPgypP8rBuAG+Y/TEnSYvOTwJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpU7MGQJKNSR5IcijJE0muafWzk+xPcrjdr231JPlskokkjyW5YOhn7Wj9DyfZceamJUmazVyOAI4DH62qtwBbgKuTnAdcCxyoqk3AgdYGeC+wqd12AbfCIDCA64F3ABcC10+HhiRp6c0aAFX1fFX9e9v+X+AQsB7YBuxp3fYAl7ftbcCXauBbwJok64BLgf1VdbSqjgH7ga2LOhtJ0pzN6z2AJOPA+cCDwBur6nkYhATwhtZtPfDs0MMmW+1kdUnSMphzACR5LfB14CNV9aNTdZ2hVqeon/g8u5IcTHJwampqrsOTJM3TnAIgySsZ/Of/laq6q5V/2E7t0O6PtPoksHHo4RuA505R/zVVdVtVba6qzWNjY/OZiyRpHuZyFVCA24FDVfXpoV37gOkreXYAdw/VP9SuBtoCvNROEd0HXJJkbXvz95JWkyQtg9Vz6PMu4M+B7yT5dqv9LXAjcEeSncAPgCvbvnuBy4AJ4CfAhwGq6miSTwIPt36fqKqjizILSdK8zRoAVfVvzHz+HuDiGfoXcPVJftZuYPd8BihJOjP8JLAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdmjUAkuxOciTJ40O1s5PsT3K43a9t9ST5bJKJJI8luWDoMTta/8NJdpyZ6UiS5mouRwBfBLaeULsWOFBVm4ADrQ3wXmBTu+0CboVBYADXA+8ALgSunw4NSdLymDUAqupfgaMnlLcBe9r2HuDyofqXauBbwJok64BLgf1VdbSqjgH7+c1QkSQtoYW+B/DGqnoeoN2/odXXA88O9ZtstZPVf0OSXUkOJjk4NTW1wOFJkmaz2G8CZ4ZanaL+m8Wq26pqc1VtHhsbW9TBSZJ+ZaEB8MN2aod2f6TVJ4GNQ/02AM+doi5JWiYLDYB9wPSVPDuAu4fqH2pXA20BXmqniO4DLkmytr35e0mrSZKWyerZOiT5KvBu4Jwkkwyu5rkRuCPJTuAHwJWt+73AZcAE8BPgwwBVdTTJJ4GHW79PVNWJbyxLkpbQrAFQVVedZNfFM/Qt4OqT/JzdwO55jU6SdMb4SWBJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnVi/3AEbR+LXfWJbnfebG9y3L80pamTwCkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6tSSfxtokq3AZ4BVwBeq6salHsOoWq5vIQW/iVRaiZY0AJKsAv4B+DNgEng4yb6qenIpxyFJczHqL6qW+gjgQmCiqr4PkGQvsA0wAFY4/waCtPIsdQCsB54dak8C71jiMWiELOcrNGmlW+oAyAy1+rUOyS5gV2v+OMlT83yOc4AXFjC2lcw598E59+Ec4IXcdFo/4w/m0mmpA2AS2DjU3gA8N9yhqm4DblvoEyQ5WFWbF/r4lcg598E592Ep57zUl4E+DGxKcm6SVwHbgX1LPAZJEkt8BFBVx5P8JXAfg8tAd1fVE0s5BknSwJJ/DqCq7gXuPYNPseDTRyuYc+6Dc+7Dks05VTV7L0nSyPGrICSpUyMVAEm2JnkqyUSSa5d7PIshycYkDyQ5lOSJJNe0+tlJ9ic53O7XtnqSfLb9Dh5LcsHyzmDhkqxK8miSe1r73CQPtjl/rV1IQJKzWnui7R9fznEvVJI1Se5M8t223u8c9XVO8tft3/XjSb6a5NWjts5Jdic5kuTxodq81zXJjtb/cJIdizG2kQmAoa+ZeC9wHnBVkvOWd1SL4jjw0ap6C7AFuLrN61rgQFVtAg60Ngzmv6nddgG3Lv2QF801wKGh9k3AzW3Ox4Cdrb4TOFZVbwZubv1Wos8A/1JVfwS8jcHcR3adk6wH/grYXFV/zODCkO2M3jp/Edh6Qm1e65rkbOB6Bh+cvRC4fjo0TktVjcQNeCdw31D7OuC65R7XGZjn3Qy+S+kpYF2rrQOeatufB64a6v9yv5V0Y/AZkQPARcA9DD5E+AKw+sT1ZnBV2Tvb9urWL8s9h3nO9/eAp08c9yivM7/6ZoCz27rdA1w6iusMjAOPL3RdgauAzw/Vf63fQm8jcwTAzF8zsX6ZxnJGtEPe84EHgTdW1fMA7f4Nrduo/B5uAT4G/LK1Xw+8WFXHW3t4Xi/Pue1/qfVfSd4ETAH/2E57fSHJaxjhda6q/wb+HvgB8DyDdXuE0V7nafNd1zOy3qMUALN+zcRKluS1wNeBj1TVj07VdYbaivo9JHk/cKSqHhkuz9C15rBvpVgNXADcWlXnA//Hr04LzGTFz7mdwtgGnAv8PvAaBqdATjRK6zybk83xjMx9lAJg1q+ZWKmSvJLBf/5fqaq7WvmHSda1/euAI60+Cr+HdwEfSPIMsJfBaaBbgDVJpj+7Mjyvl+fc9r8OOLqUA14Ek8BkVT3Y2ncyCIRRXuf3AE9X1VRV/Ry4C/gTRnudp813Xc/Ieo9SAIzk10wkCXA7cKiqPj20ax8wfSXADgbvDUzXP9SuJtgCvDR9qLlSVNV1VbWhqsYZrOP9VfVB4AHgitbtxDlP/y6uaP1X1CvDqvof4Nkkf9hKFzP4mvSRXWcGp362JPnd9u98es4ju85D5ruu9wGXJFnbjpwuabXTs9xvjizyGy2XAf8JfA/4u+UezyLN6U8ZHOo9Bny73S5jcO7zAHC43Z/d+ofB1VDfA77D4AqLZZ/Hacz/3cA9bftNwEPABPBPwFmt/urWnmj737Tc417gXN8OHGxr/c/A2lFfZ+DjwHeBx4EvA2eN2joDX2XwHsfPGbyS37mQdQX+os19AvjwYozNTwJLUqdG6RSQJGkeDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjr1/zu0eFME7m5cAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(pos_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.597e+03, 3.150e+02, 8.400e+01, 3.100e+01, 1.700e+01, 5.000e+00,\n",
       "        7.000e+00, 4.000e+00, 1.000e+00, 4.000e+00]),\n",
       " array([   8. ,  107.5,  207. ,  306.5,  406. ,  505.5,  605. ,  704.5,\n",
       "         804. ,  903.5, 1003. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAEFpJREFUeJzt3X+s3XV9x/Hna1QxUzfKKKSWuqLrNnGJQBrEsT/Y2PjlsmqiCWSRhpHUPyDDxWQp7g+chgQTFUfiiDg7cXEwpjgabGRdR2L8Q2xxBFor6xUYXNvROhi6mRhx7/1xPlcP5fb+7j3e83k+kpPz/b6/n+85n8/9NPfV749zbqoKSVJ/fmHUHZAkjYYBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASerUqlF3YCannXZabdiwYdTdkKQV5eGHH/5eVa2Zrd3PdQBs2LCBvXv3jrobkrSiJPmPubTzFJAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXq5/qTwIu1YduXR/K+T93y9pG8ryTNh0cAktQpA0CSOmUASFKnZg2AJOuTPJjkQJL9SW5o9Q8m+W6SR9rjiqF9bkwykeTxJJcO1S9rtYkk207MkCRJczGXi8AvAu+vqm8meS3wcJJdbdutVfXR4cZJzgauBN4MvA74lyS/3jZ/EvgDYBLYk2RHVX1rKQYiSZqfWQOgqg4Dh9vyD5IcANbNsMtm4O6q+hHwZJIJ4Py2baKqngBIcndrawBI0gjM6xpAkg3AucBDrXR9kkeTbE+yutXWAc8M7TbZaserH/seW5PsTbL36NGj8+meJGke5hwASV4DfBF4X1V9H7gdeCNwDoMjhI9NNZ1m95qh/tJC1R1VtamqNq1ZM+tfNJMkLdCcPgiW5BUMfvl/vqruBaiqZ4e2fxq4v61OAuuHdj8TONSWj1eXJC2zudwFFOAzwIGq+vhQfe1Qs3cC+9ryDuDKJCcnOQvYCHwD2ANsTHJWklcyuFC8Y2mGIUmar7kcAVwIvAd4LMkjrfYB4Kok5zA4jfMU8F6Aqtqf5B4GF3dfBK6rqp8AJLkeeAA4CdheVfuXcCySpHmYy11AX2P68/c7Z9jnZuDmaeo7Z9pPkrR8/CSwJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdmjUAkqxP8mCSA0n2J7mh1U9NsivJwfa8utWT5LYkE0keTXLe0Gttae0PJtly4oYlSZrNXI4AXgTeX1VvAi4ArktyNrAN2F1VG4HdbR3gcmBje2wFbodBYAA3AW8FzgdumgoNSdLymzUAqupwVX2zLf8AOACsAzYDd7ZmdwLvaMubgc/VwNeBU5KsBS4FdlXVc1X1PLALuGxJRyNJmrN5XQNIsgE4F3gIOKOqDsMgJIDTW7N1wDNDu0222vHqx77H1iR7k+w9evTofLonSZqHOQdAktcAXwTeV1Xfn6npNLWaof7SQtUdVbWpqjatWbNmrt2TJM3TnAIgySsY/PL/fFXd28rPtlM7tOcjrT4JrB/a/Uzg0Ax1SdIIzOUuoACfAQ5U1ceHNu0Apu7k2QLcN1S/ut0NdAHwQjtF9ABwSZLV7eLvJa0mSRqBVXNocyHwHuCxJI+02geAW4B7klwLPA28u23bCVwBTAA/BK4BqKrnknwY2NPafaiqnluSUUiS5m3WAKiqrzH9+XuAi6dpX8B1x3mt7cD2+XRQknRi+ElgSeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6NWsAJNme5EiSfUO1Dyb5bpJH2uOKoW03JplI8niSS4fql7XaRJJtSz8USdJ8zOUI4LPAZdPUb62qc9pjJ0CSs4ErgTe3ff46yUlJTgI+CVwOnA1c1dpKkkZk1WwNquqrSTbM8fU2A3dX1Y+AJ5NMAOe3bRNV9QRAkrtb22/Nu8eSpCWxmGsA1yd5tJ0iWt1q64BnhtpMttrx6i+TZGuSvUn2Hj16dBHdkyTNZKEBcDvwRuAc4DDwsVbPNG1rhvrLi1V3VNWmqtq0Zs2aBXZPkjSbWU8BTaeqnp1aTvJp4P62OgmsH2p6JnCoLR+vLkkagQUdASRZO7T6TmDqDqEdwJVJTk5yFrAR+AawB9iY5Kwkr2RwoXjHwrstSVqsWY8AktwFXASclmQSuAm4KMk5DE7jPAW8F6Cq9ie5h8HF3ReB66rqJ+11rgceAE4CtlfV/iUfjSRpzuZyF9BV05Q/M0P7m4Gbp6nvBHbOq3eSpBPGTwJLUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkTs0aAEm2JzmSZN9Q7dQku5IcbM+rWz1JbksykeTRJOcN7bOltT+YZMuJGY4kaa7mcgTwWeCyY2rbgN1VtRHY3dYBLgc2tsdW4HYYBAZwE/BW4HzgpqnQkCSNxqwBUFVfBZ47prwZuLMt3wm8Y6j+uRr4OnBKkrXApcCuqnquqp4HdvHyUJEkLaOFXgM4o6oOA7Tn01t9HfDMULvJVjteXZI0Ikt9ETjT1GqG+stfINmaZG+SvUePHl3SzkmSfmahAfBsO7VDez7S6pPA+qF2ZwKHZqi/TFXdUVWbqmrTmjVrFtg9SdJsFhoAO4CpO3m2APcN1a9udwNdALzQThE9AFySZHW7+HtJq0mSRmTVbA2S3AVcBJyWZJLB3Ty3APckuRZ4Gnh3a74TuAKYAH4IXANQVc8l+TCwp7X7UFUde2FZkrSMZg2AqrrqOJsunqZtAdcd53W2A9vn1TtJ0gnjJ4ElqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASerUogIgyVNJHkvySJK9rXZqkl1JDrbn1a2eJLclmUjyaJLzlmIAkqSFWYojgN+tqnOqalNb3wbsrqqNwO62DnA5sLE9tgK3L8F7S5IW6EScAtoM3NmW7wTeMVT/XA18HTglydoT8P6SpDlYbAAU8M9JHk6ytdXOqKrDAO359FZfBzwztO9kq0mSRmDVIve/sKoOJTkd2JXk2zO0zTS1elmjQZBsBXj961+/yO5Jko5nUUcAVXWoPR8BvgScDzw7dWqnPR9pzSeB9UO7nwkcmuY176iqTVW1ac2aNYvpniRpBgsOgCSvTvLaqWXgEmAfsAPY0pptAe5ryzuAq9vdQBcAL0ydKpIkLb/FnAI6A/hSkqnX+fuq+kqSPcA9Sa4Fngbe3drvBK4AJoAfAtcs4r0lSYu04ACoqieAt0xT/y/g4mnqBVy30PeTJC0tPwksSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVOL/TpoTWPDti+P7L2fuuXtI3tvSSuLRwCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKf8i2JgZ1V8j8y+RSSuPRwCS1CkDQJI6tewBkOSyJI8nmUiybbnfX5I0sKzXAJKcBHwS+ANgEtiTZEdVfWs5+6Gl57UHaeVZ7ovA5wMTVfUEQJK7gc2AAaAFGVXwgOGjlW+5A2Ad8MzQ+iTw1mXug7QkRhk+vRll2I7z0e1yB0CmqdVLGiRbga1t9X+SPD7P9zgN+N4C+raS9Thm6HPcXY45H3HM8/Src2m03AEwCawfWj8TODTcoKruAO5Y6Bsk2VtVmxa6/0rU45ihz3E75j4s15iX+y6gPcDGJGcleSVwJbBjmfsgSWKZjwCq6sUk1wMPACcB26tq/3L2QZI0sOxfBVFVO4GdJ/AtFnz6aAXrcczQ57gdcx+WZcypqtlbSZLGjl8FIUmdGqsAGNevmUiyPsmDSQ4k2Z/khlY/NcmuJAfb8+pWT5Lb2s/h0STnjXYEC5fkpCT/luT+tn5WkofamP+h3UxAkpPb+kTbvmGU/V6oJKck+UKSb7f5ftu4z3OSP2v/rvcluSvJq8ZxnpNsT3Ikyb6h2rznNsmW1v5gki2L6dPYBMDQ10xcDpwNXJXk7NH2asm8CLy/qt4EXABc18a2DdhdVRuB3W0dBj+Dje2xFbh9+bu8ZG4ADgytfwS4tY35eeDaVr8WeL6qfg24tbVbif4K+EpV/SbwFgZjH9t5TrIO+FNgU1X9FoObQ65kPOf5s8Blx9TmNbdJTgVuYvAB2vOBm6ZCY0GqaiwewNuAB4bWbwRuHHW/TtBY72PwfUqPA2tbbS3weFv+FHDVUPuftltJDwafE9kN/B5wP4MPEn4PWHXsnDO4s+xtbXlVa5dRj2Ge4/0l4Mlj+z3O88zPvh3g1DZv9wOXjus8AxuAfQudW+Aq4FND9Ze0m+9jbI4AmP5rJtaNqC8nTDvkPRd4CDijqg4DtOfTW7Nx+Vl8Avhz4P/a+q8A/11VL7b14XH9dMxt+wut/UryBuAo8LfttNffJHk1YzzPVfVd4KPA08BhBvP2MOM9z8PmO7dLOufjFACzfs3ESpfkNcAXgfdV1fdnajpNbUX9LJL8IXCkqh4eLk/TtOawbaVYBZwH3F5V5wL/y89OCUxnxY+5nb7YDJwFvA54NYPTH8cap3mei+ONc0nHP04BMOvXTKxkSV7B4Jf/56vq3lZ+Nsnatn0tcKTVx+FncSHwR0meAu5mcBroE8ApSaY+vzI8rp+OuW3/ZeC55ezwEpgEJqvqobb+BQaBMM7z/PvAk1V1tKp+DNwL/DbjPc/D5ju3Szrn4xQAY/s1E0kCfAY4UFUfH9q0A5i6C2ALg2sDU/Wr250EFwAvTB1mrhRVdWNVnVlVGxjM5b9W1R8DDwLvas2OHfPUz+Jdrf2K+p9hVf0n8EyS32ilixl8VfrYzjODUz8XJPnF9u98asxjO8/HmO/cPgBckmR1O3q6pNUWZtQXRZb4AssVwL8D3wH+YtT9WcJx/Q6Dw7xHgUfa4woG5z53Awfb86mtfRjcEfUd4DEGd1iMfByLGP9FwP1t+Q3AN4AJ4B+Bk1v9VW19om1/w6j7vcCxngPsbXP9T8DqcZ9n4C+BbwP7gL8DTh7HeQbuYnCd48cM/id/7ULmFviTNv4J4JrF9MlPAktSp8bpFJAkaR4MAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOvX/k57DuTP4pBMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(neg_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO： 分别列出训练数据中正负样本里的top 20单词（可以做适当的stop words removal）。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Text Cleaning: 文本处理部分 （10分）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(datas):\n",
    "    new_datas=[]\n",
    "    for line in datas:\n",
    "        line=line.replace('\\n','')#去除换行\n",
    "        line=re.sub(\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。？、~@#￥%……&*()《?～★∩-◎：》“”（）]+\", \"\",line)#去除标点\n",
    "        line=re.sub(\"\\d\",\"\",line)#去除数字\n",
    "        line=re.sub(\"[a-z]|[A-Z]\",\"\",line)#去除字母\n",
    "        \n",
    "        line=jieba.cut(line)\n",
    "        line=' '.join(line)\n",
    "        new_datas.append(line)\n",
    "    return new_datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO：对于train_comments, test_comments进行字符串的处理，几个考虑的点：\n",
    "#   1. 停用词过滤\n",
    "#   2. 去掉特殊符号\n",
    "#   3. 去掉数字（比如价格..)\n",
    "#   4. ...\n",
    "#   需要注意的点是，由于评论数据本身很短，如果去掉的太多，很可能字符串长度变成0\n",
    "#   预处理部分，可以自行选择合适的方.\n",
    "train_comments_new = process_text(train_comments)\n",
    "test_comments_new = process_text(test_comments)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction : 从文本中提取特征 （10分）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vec=TfidfVectorizer()\n",
    "\n",
    "x_train=vec.fit_transform(train_comments_new)\n",
    "x_test=vec.transform(test_comments_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8065, 23866) (2500, 23866) (8065,) (2500,)\n"
     ]
    }
   ],
   "source": [
    "# TODO: 利用tf-idf从文本中提取特征,写到数组里面. \n",
    "#       参考：https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "X_train =  x_train# 训练数据的特征\n",
    "y_train =  np.array(train_labels)# 训练数据的label\n",
    "X_test =   x_test# 测试数据的特征\n",
    "y_test =   np.array(test_labels)# 测试数据的label\n",
    "\n",
    "print (np.shape(X_train), np.shape(X_test), np.shape(y_train), np.shape(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling: 训练模型以及选择合适的超参数 （25分）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_t,x_v,y_t,y_v=train_test_split(X_train,y_train,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wang\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Wang\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 5}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# TODO： 利用逻辑回归来训练模型\n",
    "#       1. 评估方式： F1-score\n",
    "#       2. 超参数（hyperparater）的选择利用grid search https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "#       3. 打印出在测试数据中的最好的结果（precision, recall, f1-score, 需要分别打印出正负样本，以及综合的）\n",
    "#       请注意：做交叉验证时绝对不能用测试数据。 测试数据只能用来最后的”一次性“检验。\n",
    "#       逻辑回归的使用方法请参考：http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "#       对于逻辑回归，经常调整的超参数为： C\n",
    "from sklearn.model_selection import GridSearchCV#交叉验证\n",
    "\n",
    "lr=LogisticRegression()\n",
    "lr.fit(x_t,y_t).score(x_v,y_v)\n",
    "\n",
    "param={'C':[0.00001,0.0001,0.01,0.005,0.1,0.5,1,2,5,10]}#正则化的强度\n",
    "\n",
    "clf=GridSearchCV(lr,param,cv=5)\n",
    "clf.fit(x_t,y_t)\n",
    "clf.score(x_v,y_v)\n",
    "print(clf.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7690082644628099\n",
      "0.7288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wang\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#选好优秀值计算正确率\n",
    "model=LogisticRegression(C=5)\n",
    "model.fit(x_t,y_t)\n",
    "print(model.score(x_v,y_v))\n",
    "\n",
    "\n",
    "#进行预测\n",
    "\n",
    "print(model.score(X_test,y_test.astype('int')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-8fac17c23f72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_v\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_v\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    720\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    709\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 711\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 920\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    921\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m             train_scores = _score(estimator, X_train, y_train, scorer,\n\u001b[1;32m--> 572\u001b[1;33m                                   is_multimetric)\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[0;32m    603\u001b[0m     \"\"\"\n\u001b[0;32m    604\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_multimetric_score\u001b[1;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'item'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36m_passthrough_scorer\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_passthrough_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[1;34m\"\"\"Function that wraps estimator.score\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    288\u001b[0m         \"\"\"\n\u001b[0;32m    289\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    574\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         \"\"\"\n\u001b[1;32m--> 576\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseSVC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    577\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_dense_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_sparse_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    371\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshrinking\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_support_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 373\u001b[1;33m             self.probA_, self.probB_)\n\u001b[0m\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_compute_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "# TODO： 利用SVM来训练模型\n",
    "#       1. 评估方式： F1-score\n",
    "#       2. 超参数（hyperparater）的选择利用grid search https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "#       3. 打印出在测试数据中的最好的结果（precision, recall, f1-score, 需要分别打印出正负样本，以及综合的）\n",
    "#       请注意：做交叉验证时绝对不能用测试数据。 测试数据只能用来最后的”一次性“检验。\n",
    "#       SVM的使用方法请参考：http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "#       对于SVM模型，经常调整的超参数为：C, gamma, kernel\n",
    "sv=svm.SVC()\n",
    "c_range = [1]\n",
    "gamma_range = ['auto']\n",
    "kernel_range=['rbf']\n",
    "\n",
    "param={'C':c_range,'gamma':gamma_range,'kernel':kernel_range}\n",
    "\n",
    "clf = GridSearchCV(sv, param, cv=5)\n",
    "clf.fit(x_t,y_t)\n",
    "clf.score(x_v,y_v)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wang\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6264462809917355\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "sv=svm.SVC()\n",
    "sv.fit(x_t,y_t)\n",
    "print(sv.score(x_v,y_v))\n",
    "\n",
    "#进行预测\n",
    "\n",
    "print(sv.score(X_test,y_test.astype('int')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于超参数的调整，我们经常使用gridsearch，这也是工业界最常用的方法，但它的缺点是需要大量的计算，所以近年来这方面的研究也成为了重点。 其中一个比较经典的成果为Bayesian Optimization（利用贝叶斯的思路去寻找最好的超参数）。Ryan P. Adams主导的Bayesian Optimization利用高斯过程作为后验概率（posteior distribution）来寻找最优解。 https://papers.nips.cc/paper/4522-practical-bayesian-optimization-of-machine-learning-algorithms.pdf 在下面的练习中，我们尝试使用Bayesian Optimization工具来去寻找最优的超参数。参考工具：https://github.com/fmfn/BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 仍然使用SVM模型，但在这里使用Bayesian Optimization来寻找最好的超参数。 \n",
    "#       1. 评估方式： F1-score\n",
    "#       2. 超参数（hyperparater）的选择利用Bayesian Optimization https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "#       3. 打印出在测试数据中的最好的结果（precision, recall, f1-score, 需要分别打印出正负样本，以及综合的）\n",
    "#       请注意：做交叉验证时绝对不能用测试数据。 测试数据只能用来最后的”一次性“检验。\n",
    "#       SVM的使用方法请参考：http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "#       对于SVM模型，经常调整的超参数为：C, gamma, kernel\n",
    "#       参考Bayesian Optimization开源工具： https://github.com/fmfn/BayesianOptimization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 特征: 添加n-gram特征 (10分)\n",
    "在原有tf-idf特征的基础上，添加n-gram特征（在这里我们使用bi-gram特征）。添加完之后效果是否有提升？ 为什么？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train =  # 添加完bigram之后的特征\n",
    "y_train =  # \n",
    "X_test =   # 添加完bigram之后的特征\n",
    "y_test =   # \n",
    "\n",
    "print (np.shape(X_train), np.shape(X_test), np.shape(y_train), np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO 模型的训练，如上"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
